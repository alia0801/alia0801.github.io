---
title: "FOG: Feature-Oriented Graph Neural Networks for Tabular Data"
collection: publications
category: conferences
permalink: /publication/2025-06-15-pakdd-fog
# excerpt: 'This paper is about the number 2. The number 3 is left for future work.'
date: 2025-06-15
venue: 'Proceedings of the 2025 Pacific-Asia Conference on Knowledge Discovery and Data Mining'
slidesurl: ''
paperurl: 'https://link.springer.com/chapter/10.1007/978-981-96-8298-0_3'
citation: "Teng-Yuan Tsou, Pei-Xuan Li, Fandel Lin, Hsun-Ping Hsieh*. FOG: Feature-Oriented Graph Neural Networks for Tabular Data. In Proceedings of the 2025 Pacific-Asia Conference on Knowledge Discovery and Data Mining, 2025 (PAKDD '25)"
---

Recent advancements in graph neural networks (GNNs) have highlighted their potential for addressing challenges in tabular data prediction by capturing complex inter-sample relationships and relaxing the traditional independent and identically distributed (i.i.d.) assumption. In this work, we present a novel GNN architecture, Feature-Oriented Graph Neural Networks (FOG), specifically designed for tabular data prediction. The FOG model transforms tabular data into feature-oriented graphs and incorporates a feature importance learner to identify distinct feature importance patterns across different samples, enabling it to effectively capture intricate sample interactions. Experimental results demonstrate that FOG achieves state-of-the-art performance on various real-world and synthetic datasets. It accurately identifies key features and delivers feature importance assessments that are highly consistent with those produced by traditional interpretable tree-based models. Additionally, experiments reveal that FOG effectively identifies distinct feature importance patterns across different samples, further enhancing its ability to capture intricate sample interactions. The FOG model aligns with recent trends in GNN-based tabular data prediction, offering an innovative solution that combines enhanced predictive performance with improved interpretability.
